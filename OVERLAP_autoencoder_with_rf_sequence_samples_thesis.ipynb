{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyljbs7jXjnklrs5+sH9y0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenafc/MscThesis_EyeTrackingIVR/blob/main/OVERLAP_autoencoder_with_rf_sequence_samples_thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from torch.utils.data import TensorDataset\n"
      ],
      "metadata": {
        "id": "Hm_d1GsOmke4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:', device)\n",
        "\n",
        "# Read the CSV file\n",
        "file_name = '/content/LLA2020_labeled.csv'\n",
        "# file_name = '/content/eye_tracking_data_small_2019.csv'\n",
        "eye_tracking_data = pd.read_csv(file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpDf-1Hxmomv",
        "outputId": "30f23f12-6bc2-478f-8ed3-ec658fd53a55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eye_tracking_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ghlLMn_o3jTY",
        "outputId": "400cbaac-b249-4d4b-80ba-d6b8fba7240d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    time    L_x     L_y     L_z     C_x     C_y     C_z  observer  GT1  GT2  \\\n",
              "0  9.314 -2.969  1.6232 -1.2434 -0.4009  1.6289 -1.2939         1    0    0   \n",
              "1  9.337 -2.969  1.6255 -1.2432 -0.4007  1.6290 -1.2940         1    0    0   \n",
              "2  9.360 -2.969  1.6260 -1.2447 -0.4006  1.6290 -1.2940         1    0    0   \n",
              "3  9.381 -2.969  1.6232 -1.2430 -0.4004  1.6291 -1.2941         1    0    0   \n",
              "4  9.403 -2.969  1.6242 -1.2410 -0.4002  1.6291 -1.2941         1    0    0   \n",
              "\n",
              "   GT3  GT4  GT5  GT6  GT7  \n",
              "0    0    0    0    0    0  \n",
              "1    0    0    0    0    0  \n",
              "2    0    0    0    0    0  \n",
              "3    0    0    0    0    0  \n",
              "4    0    0    0    0    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e21ab37d-a408-4c06-a1c1-2dcdee9ebfac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>L_x</th>\n",
              "      <th>L_y</th>\n",
              "      <th>L_z</th>\n",
              "      <th>C_x</th>\n",
              "      <th>C_y</th>\n",
              "      <th>C_z</th>\n",
              "      <th>observer</th>\n",
              "      <th>GT1</th>\n",
              "      <th>GT2</th>\n",
              "      <th>GT3</th>\n",
              "      <th>GT4</th>\n",
              "      <th>GT5</th>\n",
              "      <th>GT6</th>\n",
              "      <th>GT7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.314</td>\n",
              "      <td>-2.969</td>\n",
              "      <td>1.6232</td>\n",
              "      <td>-1.2434</td>\n",
              "      <td>-0.4009</td>\n",
              "      <td>1.6289</td>\n",
              "      <td>-1.2939</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.337</td>\n",
              "      <td>-2.969</td>\n",
              "      <td>1.6255</td>\n",
              "      <td>-1.2432</td>\n",
              "      <td>-0.4007</td>\n",
              "      <td>1.6290</td>\n",
              "      <td>-1.2940</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.360</td>\n",
              "      <td>-2.969</td>\n",
              "      <td>1.6260</td>\n",
              "      <td>-1.2447</td>\n",
              "      <td>-0.4006</td>\n",
              "      <td>1.6290</td>\n",
              "      <td>-1.2940</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.381</td>\n",
              "      <td>-2.969</td>\n",
              "      <td>1.6232</td>\n",
              "      <td>-1.2430</td>\n",
              "      <td>-0.4004</td>\n",
              "      <td>1.6291</td>\n",
              "      <td>-1.2941</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.403</td>\n",
              "      <td>-2.969</td>\n",
              "      <td>1.6242</td>\n",
              "      <td>-1.2410</td>\n",
              "      <td>-0.4002</td>\n",
              "      <td>1.6291</td>\n",
              "      <td>-1.2941</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e21ab37d-a408-4c06-a1c1-2dcdee9ebfac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e21ab37d-a408-4c06-a1c1-2dcdee9ebfac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e21ab37d-a408-4c06-a1c1-2dcdee9ebfac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-269a6bba-8a6f-4e65-aa34-8a825f71f7d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-269a6bba-8a6f-4e65-aa34-8a825f71f7d1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-269a6bba-8a6f-4e65-aa34-8a825f71f7d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "eye_tracking_data"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eye_tracking_data_rf = eye_tracking_data.copy()"
      ],
      "metadata": {
        "id": "_obyjfa6p_2D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning\n",
        "eye_tracking_data = eye_tracking_data.drop(columns=['GT2', 'GT3', 'GT4', 'GT5', 'GT6', 'GT7']) # removing\n",
        "eye_tracking_data = eye_tracking_data[['time', 'L_x', 'L_y', 'L_z', 'C_x', 'C_y', 'C_z', 'GT1','observer']]"
      ],
      "metadata": {
        "id": "r8yFHKhSrhlz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(eye_tracking_data.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csBo82UhsgWw",
        "outputId": "6af71163-73bf-4fb7-ac5f-a58d991b7732"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    time    L_x     L_y     L_z     C_x     C_y     C_z  GT1  observer\n",
            "0  9.314 -2.969  1.6232 -1.2434 -0.4009  1.6289 -1.2939    0         1\n",
            "1  9.337 -2.969  1.6255 -1.2432 -0.4007  1.6290 -1.2940    0         1\n",
            "2  9.360 -2.969  1.6260 -1.2447 -0.4006  1.6290 -1.2940    0         1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FEATURES"
      ],
      "metadata": {
        "id": "aoXlq8dvh0Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eye_tracking_data_without_GT1 = eye_tracking_data.drop(columns=['GT1'])"
      ],
      "metadata": {
        "id": "KVisdpykrw26"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(eye_tracking_data_without_GT1.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cLUvgTGsZzw",
        "outputId": "e8790277-1a8f-44ee-e4c8-005c7a64c75f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    time    L_x     L_y     L_z     C_x     C_y     C_z  observer\n",
            "0  9.314 -2.969  1.6232 -1.2434 -0.4009  1.6289 -1.2939         1\n",
            "1  9.337 -2.969  1.6255 -1.2432 -0.4007  1.6290 -1.2940         1\n",
            "2  9.360 -2.969  1.6260 -1.2447 -0.4006  1.6290 -1.2940         1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-7qM3-vAmGcX"
      },
      "outputs": [],
      "source": [
        "# X train and X test without GT1\n",
        "\n",
        "# Convert all columns to float32 for compatibility with PyTorch\n",
        "eye_tracking_data_without_GT1 = eye_tracking_data_without_GT1.astype('float32')\n",
        "\n",
        "train_split = 0.75\n",
        "# Creating data indices for training and test splits: LSTM autoencoder time series https://github.com/fabiozappo/LSTM-Autoencoder-Time-Series/blob/main/code/main.py\n",
        "dataset_size = len(eye_tracking_data_without_GT1)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(train_split * dataset_size))\n",
        "\n",
        "et_train_without_GT1 = eye_tracking_data_without_GT1.iloc[:split, :]\n",
        "et_test_without_GT1 = eye_tracking_data_without_GT1.iloc[split:, :]\n",
        "\n",
        "# Define sequence length (the sequences have overlapping data)\n",
        "sequence_length = 460  # 10 seconds of data - sampled at ~45 Hz\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LABEL - GT1"
      ],
      "metadata": {
        "id": "t-AOIOQ0iLMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eye_tracking_data_GT1 = eye_tracking_data[['GT1']]\n",
        "print(eye_tracking_data_GT1.head(3))\n",
        "print(eye_tracking_data.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46YnrW7hGTH8",
        "outputId": "1b1a1c91-7644-4a8a-82ff-8ca34dd40b8d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   GT1\n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "(106252, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all columns to float32 for compatibility with PyTorch\n",
        "eye_tracking_data_GT1 = eye_tracking_data_GT1.astype('float32')\n",
        "\n",
        "train_split = 0.75\n",
        "dataset_size = len(eye_tracking_data_GT1)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(train_split * dataset_size))\n",
        "\n",
        "et_train_GT1 = eye_tracking_data_GT1.iloc[:split, :]\n",
        "et_test_GT1 = eye_tracking_data_GT1.iloc[split:, :]\n",
        "\n"
      ],
      "metadata": {
        "id": "x6ZKAg_pIbR8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New sequence - 2 dimensions - overlapping"
      ],
      "metadata": {
        "id": "s1pj20DOg11H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #new sequence - overlapping:\n",
        "\n",
        "def subset_training_data_overlap_by_rows(\n",
        "    training_data_overlap: pd.DataFrame, rows_interval: int = 460, rows_overlap: int = 135\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Splits the training_data DataFrame into overlapping subsets for each observer, using row-based intervals.\n",
        "    Parameters: training_data_overlap (pd.DataFrame): The input DataFrame with an 'observer' column.\n",
        "                rows_interval (int): The number of rows for each subset.\n",
        "                rows_overlap (int): The number of overlapping rows for the next subset.\n",
        "    Returns: pd.DataFrame: A new DataFrame with repeated overlapping rows for each observer, using global subset IDs.\n",
        "    \"\"\"\n",
        "    # Ensure the data is sorted by observer and time\n",
        "    training_data_overlap = training_data_overlap.sort_values(by=[\"observer\", \"time\"]).reset_index(drop=True)\n",
        "\n",
        "    all_subsets = []\n",
        "    global_subset_id = 1\n",
        "\n",
        "    # Iterate over each observer\n",
        "    for observer_id, observer_data in training_data_overlap.groupby(\"observer\"):\n",
        "        observer_data = observer_data.reset_index(drop=True)\n",
        "\n",
        "        # Calculate the step for each subset\n",
        "        subset_step = rows_interval - rows_overlap\n",
        "        n_rows = len(observer_data)\n",
        "\n",
        "        # Create subsets using slicing\n",
        "        for start_idx in range(0, n_rows, subset_step):\n",
        "            end_idx = start_idx + rows_interval\n",
        "            current_subset = observer_data.iloc[start_idx:end_idx].copy()\n",
        "\n",
        "            if not current_subset.empty:\n",
        "                # Label this subset with a unique global subset ID\n",
        "                current_subset[\"subset\"] = global_subset_id\n",
        "                all_subsets.append(current_subset)\n",
        "                global_subset_id += 1\n",
        "\n",
        "    # Concatenate all subsets into one DataFrame\n",
        "    df = pd.concat(all_subsets, ignore_index=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7XH2CKe26tTC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FEATURES WITH OVERLAPPING - TEST DATA WILL NOT BE OVERLAPPED"
      ],
      "metadata": {
        "id": "Kld9qwp1nq_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### REMOVE GT1, ## SPLIT TRAIN/TEST, than overlap: et_train_without_GT1\n",
        "\n",
        "### OVERLAP TRAINING DATA\n",
        "et_train_without_GT1_overlap = subset_training_data_overlap_by_rows(et_train_without_GT1)\n",
        "print(f\"et_train_without_GT1_overlap shape is: {et_train_without_GT1_overlap.shape}\")\n",
        "\n",
        "### OVERLAP TEST DATA\n",
        "et_test_without_GT1_overlap = subset_training_data_overlap_by_rows(et_test_without_GT1)\n",
        "print(f\"et_train_without_GT1_overlap shape is: {et_train_without_GT1_overlap.shape}\")\n",
        "\n",
        "# Convert all columns to float32 for compatibility with PyTorch\n",
        "# eye_tracking_data_without_GT1_overlap = et_train_without_GT1_overlap.astype('float32')\n",
        "et_train_without_GT1_overlap = et_train_without_GT1_overlap.astype('float32')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXAr4dQ6uk0X",
        "outputId": "5fa83b84-41e9-49db-9e06-7e882ff2168a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "et_train_without_GT1_overlap shape is: (108821, 9)\n",
            "et_train_without_GT1_overlap shape is: (108821, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FEATURES OVERLAPPED IN THE **ENCODER**"
      ],
      "metadata": {
        "id": "_s25O4A_2veE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting in numpy array for the tensors\n",
        "X_train_seq = et_train_without_GT1_overlap.values\n",
        "X_2_train_seq = X_train_seq.copy() # it was x_train_seq\n",
        "X_test_seq = et_test_without_GT1_overlap.values                        ### NO OVERLAP TEST DATA\n",
        "X_2_test_seq = X_test_seq.copy() # it was y_test_seq\n",
        "\n",
        "# y_train_seq_GT1 = et_train_GT1_overlap.values # it was x_train_seq   #### NO NEED LABELS FOR THE AUTOENCODEDRS!!\n",
        "# y_2_train_seq_GT1 = y_train_seq_GT1.copy() # it was y_train_seq\n",
        "# y_test_seq_GT1 = et_test_GT1_overlap.values # it was x_test_seq\n",
        "# y_2_test_seq_GT1 = y_test_seq_GT1.copy() # it was y_train_seq\n",
        "\n",
        "print(f\"X_train_seq shape: {X_train_seq.shape}\")\n",
        "print(f\"X_2_train_seq shape: {X_2_train_seq.shape}\\n\")\n",
        "print(f\"X_test_seq shape: {X_test_seq.shape}\")                       ### NO OVERLAP TEST DATA\n",
        "print(f\"X_2_test_seq shape: {X_2_test_seq.shape}\\n\")\n",
        "\n",
        "# print(f\"y_train_seq_GT1 shape: {y_train_seq_GT1.shape}\")     #### NO NEED LABELS FOR THE AUTOENCODEDRS!!\n",
        "# print(f\"y_2_train_seq_GT1 shape: {y_train_seq_GT1.shape}\\n\")\n",
        "# print(f\"y_test_seq_GT1 shape: {y_test_seq_GT1.shape}\")\n",
        "# print(f\"y_2_test_seq_GT1 shape: {y_2_test_seq_GT1.shape}\")"
      ],
      "metadata": {
        "id": "lqNGioBWfXNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ddd339-01db-4896-f899-fd3f30e89865"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_seq shape: (108821, 9)\n",
            "X_2_train_seq shape: (108821, 9)\n",
            "\n",
            "X_test_seq shape: (36144, 9)\n",
            "X_2_test_seq shape: (36144, 9)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T27NYbISRdnO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32)\n",
        "X_2_train_tensor = X_train_tensor.clone()  # Target for the autoencoder is the input itself\n",
        "X_test_tensor = torch.tensor(X_test_seq, dtype=torch.float32)\n",
        "X_2_test_tensor = X_test_tensor.clone()  # Target for the autoencoder is the input itself\n",
        "\n",
        "# Create TensorDataset for train and test sets\n",
        "train_dataset = TensorDataset(X_train_tensor, X_2_train_tensor) # IT WAS Y_TRAIN_TENSOR AND Y_TEST_TENSOR\n",
        "test_dataset = TensorDataset(X_test_tensor, X_2_test_tensor)\n",
        "\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True) #timeseries data so shuffle = False\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True) #timeseries data so shuffle = False\n",
        "\n",
        "print(f\"X_train_tensor shape: {X_train_tensor.shape}\")\n",
        "print(f\"X_2_train_tensor shape: {X_2_train_tensor.shape}\\n\")\n",
        "print(f\"X_test_tensor shape: {X_test_tensor.shape}\")\n",
        "print(f\"X_2_test_tensor shape: {X_2_test_tensor.shape}\")"
      ],
      "metadata": {
        "id": "OtD9XSEMmjJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6aec87-8907-4d96-ee99-aca2806a2042"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_tensor shape: torch.Size([108821, 9])\n",
            "X_2_train_tensor shape: torch.Size([108821, 9])\n",
            "\n",
            "X_test_tensor shape: torch.Size([36144, 9])\n",
            "X_2_test_tensor shape: torch.Size([36144, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQm3j--Qu0zO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AUTOENCODER MODEL"
      ],
      "metadata": {
        "id": "1vZ2uBit25em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters for the autoencoder model\n",
        "random_seed = 123\n",
        "learning_rate = 0.005\n",
        "num_epochs = 5\n",
        "\n",
        "# Model architecture settings\n",
        "input_size = 9                                                                             # 460 samples * 8 features per sample (I am including the column \"observer\") = 3220\n",
        "num_hidden_1 = 500  # First layer in encoder\n",
        "num_hidden_2 = 50   # Compressed representation layer\n",
        "\n",
        "# Define the Autoencoder model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        ### ENCODER\n",
        "        self.encoder_layer1 = nn.Linear(input_size, num_hidden_1)\n",
        "        self.encoder_layer2 = nn.Linear(num_hidden_1, num_hidden_2)\n",
        "\n",
        "        ### DECODER\n",
        "        self.decoder_layer1 = nn.Linear(num_hidden_2, num_hidden_1)\n",
        "        self.decoder_layer2 = nn.Linear(num_hidden_1, input_size)\n",
        "        # self.decoder_layer2.weight.detach().normal_(0.0, 0.1)\n",
        "        # self.decoder_layer2.bias.detach().zero_()\n",
        "\n",
        "    def encoder(self, x):\n",
        "        x = F.sigmoid(self.encoder_layer1(x))\n",
        "        encoded = F.sigmoid(self.encoder_layer2(x))\n",
        "        return encoded\n",
        "\n",
        "    def decoder(self, encoded_x):\n",
        "        x = F.leaky_relu(self.decoder_layer1(encoded_x))\n",
        "        decoded = torch.sigmoid(self.decoder_layer2(x))  # Sigmoid to get values between 0 and 1\n",
        "        return decoded\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten input from (batch, sequence_length, features) to (batch, input_size)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "# Instantiate the model\n",
        "torch.manual_seed(random_seed)\n",
        "model = Autoencoder().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training Loop\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (sequences, _) in enumerate(train_loader):\n",
        "        sequences = sequences.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        decoded = model(sequences)\n",
        "\n",
        "        # loss = F.binary_cross_entropy(decoded, sequences.view(sequences.size(0), -1), reduction='mean')\n",
        "         # reconstruction error\n",
        "        loss = F.mse_loss(decoded, sequences.view(sequences.size(0), -1)) # changes binary_cross_entropy loss to mse_loss\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Logging\n",
        "        if not batch_idx % 50:\n",
        "            print('Epoch: %03d/%03d | Batch %03d/%03d | Loss: %.4f'\n",
        "                  % (epoch + 1, num_epochs, batch_idx, len(train_loader), loss))\n",
        "\n",
        "    print('Time elapsed: %.2f min' % ((time.time() - start_time) / 60))\n",
        "\n",
        "print('Total Training Time: %.2f min' % ((time.time() - start_time) / 60))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXU7SNjOmceG",
        "outputId": "75c6691e-d427-4f92-b1b3-136d7ed60c4a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/005 | Batch 000/425 | Loss: 18.0179\n",
            "Epoch: 001/005 | Batch 050/425 | Loss: 259.0796\n",
            "Epoch: 001/005 | Batch 100/425 | Loss: 519.0620\n",
            "Epoch: 001/005 | Batch 150/425 | Loss: 1274.3918\n",
            "Epoch: 001/005 | Batch 200/425 | Loss: 2013.5337\n",
            "Epoch: 001/005 | Batch 250/425 | Loss: 3017.6548\n",
            "Epoch: 001/005 | Batch 300/425 | Loss: 4542.4722\n",
            "Epoch: 001/005 | Batch 350/425 | Loss: 5956.7300\n",
            "Epoch: 001/005 | Batch 400/425 | Loss: 7772.0312\n",
            "Time elapsed: 0.20 min\n",
            "Epoch: 002/005 | Batch 000/425 | Loss: 15.6600\n",
            "Epoch: 002/005 | Batch 050/425 | Loss: 259.0796\n",
            "Epoch: 002/005 | Batch 100/425 | Loss: 519.0620\n",
            "Epoch: 002/005 | Batch 150/425 | Loss: 1274.3918\n",
            "Epoch: 002/005 | Batch 200/425 | Loss: 2013.5337\n",
            "Epoch: 002/005 | Batch 250/425 | Loss: 3017.6548\n",
            "Epoch: 002/005 | Batch 300/425 | Loss: 4542.4722\n",
            "Epoch: 002/005 | Batch 350/425 | Loss: 5956.7300\n",
            "Epoch: 002/005 | Batch 400/425 | Loss: 7772.0312\n",
            "Time elapsed: 0.38 min\n",
            "Epoch: 003/005 | Batch 000/425 | Loss: 15.6600\n",
            "Epoch: 003/005 | Batch 050/425 | Loss: 259.0796\n",
            "Epoch: 003/005 | Batch 100/425 | Loss: 519.0620\n",
            "Epoch: 003/005 | Batch 150/425 | Loss: 1274.3918\n",
            "Epoch: 003/005 | Batch 200/425 | Loss: 2013.5337\n",
            "Epoch: 003/005 | Batch 250/425 | Loss: 3017.6548\n",
            "Epoch: 003/005 | Batch 300/425 | Loss: 4542.4722\n",
            "Epoch: 003/005 | Batch 350/425 | Loss: 5956.7300\n",
            "Epoch: 003/005 | Batch 400/425 | Loss: 7772.0312\n",
            "Time elapsed: 0.55 min\n",
            "Epoch: 004/005 | Batch 000/425 | Loss: 15.6600\n",
            "Epoch: 004/005 | Batch 050/425 | Loss: 259.0796\n",
            "Epoch: 004/005 | Batch 100/425 | Loss: 519.0620\n",
            "Epoch: 004/005 | Batch 150/425 | Loss: 1274.3918\n",
            "Epoch: 004/005 | Batch 200/425 | Loss: 2013.5337\n",
            "Epoch: 004/005 | Batch 250/425 | Loss: 3017.6548\n",
            "Epoch: 004/005 | Batch 300/425 | Loss: 4542.4722\n",
            "Epoch: 004/005 | Batch 350/425 | Loss: 5956.7300\n",
            "Epoch: 004/005 | Batch 400/425 | Loss: 7772.0312\n",
            "Time elapsed: 0.73 min\n",
            "Epoch: 005/005 | Batch 000/425 | Loss: 15.6600\n",
            "Epoch: 005/005 | Batch 050/425 | Loss: 259.0796\n",
            "Epoch: 005/005 | Batch 100/425 | Loss: 519.0620\n",
            "Epoch: 005/005 | Batch 150/425 | Loss: 1274.3918\n",
            "Epoch: 005/005 | Batch 200/425 | Loss: 2013.5337\n",
            "Epoch: 005/005 | Batch 250/425 | Loss: 3017.6548\n",
            "Epoch: 005/005 | Batch 300/425 | Loss: 4542.4722\n",
            "Epoch: 005/005 | Batch 350/425 | Loss: 5956.7300\n",
            "Epoch: 005/005 | Batch 400/425 | Loss: 7772.0312\n",
            "Time elapsed: 0.90 min\n",
            "Total Training Time: 0.90 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using encoder with the overlapped features\n"
      ],
      "metadata": {
        "id": "FaYUiJWNWjap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### USING ENCODER\n",
        "\n",
        "# Extract features from the autoencoder for Random Forest\n",
        "X_train_ae_overlap = np.ones((len(train_dataset), num_hidden_2))\n",
        "# y_train_ae = y_train_seq\n",
        "X_2_train_ae_overlap = np.ones((len(train_dataset),num_hidden_2)) # it was y_train_ae_seq\n",
        "\n",
        "X_test_ae_overlap = np.ones((len(test_dataset), num_hidden_2))\n",
        "# y_test_ae = y_test_seq\n",
        "X_2_test_ae_overlap = np.ones((len(test_dataset),num_hidden_2)) # it was y_test_ae_seq\n",
        "\n",
        "start_idx = 0\n",
        "for idx, (sequences, labels) in enumerate(train_loader):\n",
        "    sequences = sequences.to(device)\n",
        "    encoded = model.encoder(sequences.view(sequences.size(0), -1))\n",
        "    # decoded = model.encoder(sequences.view(sequences.size(0), -1))\n",
        "\n",
        "    batch_size = encoded.shape[0]\n",
        "    # batch_size = decoded.shape[0]\n",
        "    # X_train_ae[start_idx:start_idx+batch_size] = decoded.cpu().detach().numpy() #using decoder\n",
        "    # y_train_ae[start_idx:start_idx+batch_size] = decoded.cpu().detach().numpy() #using decoder #labels.cpu().detach().numpy()\n",
        "    X_train_ae_overlap[start_idx:start_idx+batch_size] = encoded.cpu().detach().numpy() #using encoder\n",
        "    X_2_train_ae_overlap[start_idx:start_idx+batch_size] = encoded.cpu().detach().numpy() #using encoder #labels.cpu().detach().numpy()\n",
        "    start_idx += batch_size\n",
        "\n",
        "start_idx = 0\n",
        "for idx, (sequences, labels) in enumerate(test_loader):\n",
        "    sequences = sequences.to(device)\n",
        "    # encoded = model.encoder(sequences.view(sequences.size(0), -1))\n",
        "    decoded = model.encoder(sequences.view(sequences.size(0), -1))\n",
        "    # batch_size = encoded.shape[0]\n",
        "    batch_size = decoded.shape[0]\n",
        "    X_test_ae_overlap[start_idx:start_idx + batch_size] = decoded.cpu().detach().numpy() #using encoder\n",
        "    X_2_test_ae_overlap[start_idx:start_idx+batch_size] = decoded.cpu().detach().numpy() #using encoder #labels.cpu().detach().numpy()\n",
        "    # X_test_ae[start_idx:start_idx+batch_size] = decoded.cpu().detach().numpy() #using decoder\n",
        "    # y_test_ae[start_idx:start_idx+batch_size] = decoded.cpu().detach().numpy() #using decoder #labels.cpu().detach().numpy()\n",
        "\n",
        "    start_idx += batch_size\n"
      ],
      "metadata": {
        "id": "3iUFyA8QWE8A"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OVERLAPPING THE LABEL GT1 - Y TRAIN -\n",
        "###(NEED TO OVERLAP THE DATASET BEFORE SEPARATE THE FEATURES AND LABELS BECAUSE OF THE COLUMN OBSERVER IN THE FUNCTION subset_training_data_overlap_by_rows)"
      ],
      "metadata": {
        "id": "79wq5zak3Jdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## SPLIT TRAIN/TEST, than overlap: et_train_GT1\n",
        "eye_tracking_data_complete = eye_tracking_data.astype('float32')\n",
        "\n",
        "train_split = 0.75\n",
        "dataset_size = len(eye_tracking_data_complete)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(train_split * dataset_size))\n",
        "\n",
        "et_train_complete = eye_tracking_data_complete.iloc[:split, :]\n",
        "# et_test_GT1 = eye_tracking_data_GT1.iloc[split:, :]\n",
        "### OVERLAP COMPLETE DATA - NOT POSSIBLE ONLY GT1 BECAUSE THERE IS NO OBSERVER COLUMN\n",
        "\n",
        "et_train_complete_overlap = subset_training_data_overlap_by_rows(et_train_complete)\n",
        "print(f\"et_train_complete_overlap shape is: {et_train_complete_overlap.shape}\\n\")\n",
        "print(et_train_complete_overlap.head(3))\n",
        "\n",
        "### then REMOVE FEATUES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNqp97d73QtI",
        "outputId": "4b04dbc4-5a4e-49f1-f6b4-d16f97056f26"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "et_train_complete_overlap shape is: (108821, 10)\n",
            "\n",
            "    time    L_x     L_y     L_z     C_x     C_y     C_z  GT1  observer  subset\n",
            "0  9.314 -2.969  1.6232 -1.2434 -0.4009  1.6289 -1.2939  0.0       1.0       1\n",
            "1  9.337 -2.969  1.6255 -1.2432 -0.4007  1.6290 -1.2940  0.0       1.0       1\n",
            "2  9.360 -2.969  1.6260 -1.2447 -0.4006  1.6290 -1.2940  0.0       1.0       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all columns to float32 for compatibility with PyTorch\n",
        "\n",
        "et_train_GT1_overlap = et_train_complete_overlap[['GT1']]\n",
        "\n",
        "print(f\"et_train_GT1_overlap shape is: {et_train_GT1_overlap.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUiZctUGHCkD",
        "outputId": "57fc0ec8-3331-4662-8262-ba06b9051db6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "et_train_GT1_overlap shape is: (108821, 1)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RANDOM FOREST"
      ],
      "metadata": {
        "id": "mMPXkv4jAzid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eye_tracking_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyM8NkIMAyhs",
        "outputId": "552833e2-fabf-4a5b-9ae6-89bf591a7874"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['time', 'L_x', 'L_y', 'L_z', 'C_x', 'C_y', 'C_z', 'GT1', 'observer'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### USING ENCODER IN X TEST WITH NO OVERLAPPING"
      ],
      "metadata": {
        "id": "YTfSsisisbes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting in numpy array for the tensors\n",
        "X_train_orig = et_train_without_GT1.values\n",
        "X_2_train_orig = X_train_orig.copy() # it was x_train_seq\n",
        "X_test_orig = et_test_without_GT1.values\n",
        "X_2_test_orig = X_test_orig.copy() # it was y_test_seq\n",
        "\n",
        "# y_train_seq_GT1 = et_train_GT1_overlap.values # it was x_train_seq #### NO NEED LABELS FOR THE AUTOENCODEDRS!!\n",
        "# y_2_train_seq_GT1 = y_train_seq_GT1.copy() # it was y_train_seq\n",
        "# y_test_seq_GT1 = et_test_GT1_overlap.values # it was x_test_seq\n",
        "# y_2_test_seq_GT1 = y_test_seq_GT1.copy() # it was y_train_seq\n",
        "\n",
        "print(f\"X_train_orig shape: {X_train_orig.shape}\")\n",
        "print(f\"X_2_train_orig shape: {X_2_train_orig.shape}\\n\")\n",
        "print(f\"X_test_orig shape: {X_test_orig.shape}\")\n",
        "print(f\"X_2_test_orig shape: {X_2_test_orig.shape}\\n\")\n",
        "\n",
        "# print(f\"y_train_seq_GT1 shape: {y_train_seq_GT1.shape}\") #### NO NEED LABELS FOR THE AUTOENCODEDRS!!\n",
        "# print(f\"y_2_train_seq_GT1 shape: {y_train_seq_GT1.shape}\\n\")\n",
        "# print(f\"y_test_seq_GT1 shape: {y_test_seq_GT1.shape}\")\n",
        "# print(f\"y_2_test_seq_GT1 shape: {y_2_test_seq_GT1.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgsLquYa7Ykv",
        "outputId": "1ac858d2-1f0b-499d-c87c-e991d09797ca"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_orig shape: (79689, 8)\n",
            "X_2_train_orig shape: (79689, 8)\n",
            "\n",
            "X_test_orig shape: (26563, 8)\n",
            "X_2_test_orig shape: (26563, 8)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor_orig = torch.tensor(X_train_orig, dtype=torch.float32)\n",
        "X_2_train_tensor_orig = X_train_tensor_orig.clone()  # Target for the autoencoder is the input itself\n",
        "X_test_tensor_orig = torch.tensor(X_test_orig, dtype=torch.float32)\n",
        "X_2_test_tensor_orig = X_test_tensor_orig.clone()  # Target for the autoencoder is the input itself\n",
        "\n",
        "# Create TensorDataset for train and test sets\n",
        "train_dataset_orig = TensorDataset(X_train_tensor_orig, X_2_train_tensor_orig) # IT WAS Y_TRAIN_TENSOR AND Y_TEST_TENSOR\n",
        "test_dataset_orig = TensorDataset(X_test_tensor_orig, X_2_test_tensor_orig)\n",
        "\n",
        "batch_size = 256\n",
        "train_loader_orig = DataLoader(train_dataset_orig, batch_size=batch_size, shuffle=False, drop_last=True) #timeseries data so shuffle = False\n",
        "test_loader_orig = DataLoader(test_dataset_orig, batch_size=batch_size, shuffle=False, drop_last=True) #timeseries data so shuffle = False\n",
        "\n",
        "print(f\"X_train_tensor_orig shape: {X_train_tensor_orig.shape}\")\n",
        "print(f\"X_2_train_tensor_orig shape: {X_2_train_tensor_orig.shape}\\n\")\n",
        "print(f\"X_test_tensor_orig shape: {X_test_tensor_orig.shape}\")\n",
        "print(f\"X_2_test_tensor_orig shape: {X_2_test_tensor_orig.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-So0cY997gSQ",
        "outputId": "d36d6793-57be-4ff8-a41b-a70d65a86bb8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_tensor_orig shape: torch.Size([79689, 8])\n",
            "X_2_train_tensor_orig shape: torch.Size([79689, 8])\n",
            "\n",
            "X_test_tensor_orig shape: torch.Size([26563, 8])\n",
            "X_2_test_tensor_orig shape: torch.Size([26563, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### USING ENCODER - SO WE CAN INSERT X TEST WITH NO SEQUENCES IN THE RF MODEL\n",
        "\n",
        "# Extract features from the autoencoder for Random Forest\n",
        "X_train_ae_orig = np.ones((len(train_dataset_orig), num_hidden_2))\n",
        "# y_train_ae = y_train_seq\n",
        "y_train_ae_orig = np.ones((len(train_dataset_orig),num_hidden_2))\n",
        "\n",
        "X_test_ae_orig = np.ones((len(test_dataset_orig), num_hidden_2))\n",
        "# y_test_ae = y_test_seq\n",
        "y_test_ae_orig = np.ones((len(test_dataset_orig),num_hidden_2))\n",
        "\n",
        "start_idx = 0\n",
        "for idx, (sequences, labels) in enumerate(train_loader_orig):\n",
        "    sequences = sequences.to(device)\n",
        "    encoded = model.encoder(sequences.view(sequences.size(0), -1))\n",
        "    # decoded = model.encoder(sequences.view(sequences.size(0), -1))\n",
        "\n",
        "    batch_size = encoded.shape[0]\n",
        "    # batch_size = decoded.shape[0]\n",
        "    # X_train_ae[start_idx:start_idx+batch_size] = decoded.cpu().detach().numpy() #using decoder\n",
        "    # y_train_ae[start_idx:start_idx+batch_size] = decoded.cpu().detach().numpy() #using decoder #labels.cpu().detach().numpy()\n",
        "    X_train_ae_orig[start_idx:start_idx+batch_size] = encoded.cpu().detach().numpy() #using encoder\n",
        "    y_train_ae_orig[start_idx:start_idx+batch_size] = encoded.cpu().detach().numpy() #using encoder #labels.cpu().detach().numpy()\n",
        "    start_idx += batch_size\n",
        "\n",
        "start_idx = 0\n",
        "for idx, (sequences, labels) in enumerate(test_loader_orig):\n",
        "    sequences = sequences.to(device)\n",
        "    # encoded = model.encoder(sequences.view(sequences.size(0), -1))\n",
        "    decoded = model.encoder(sequences.view(sequences.size(0), -1))\n",
        "    # batch_size = encoded.shape[0]\n",
        "    batch_size = decoded.shape[0]\n",
        "    X_test_ae_orig[start_idx:start_idx + batch_size] = decoded.cpu().detach().numpy() #using encoder\n",
        "    y_test_ae_orig[start_idx:start_idx+batch_size] = decoded.cpu().detach().numpy() #using encoder #labels.cpu().detach().numpy()\n",
        "    # X_test_ae[start_idx:start_idx+batch_size] = decoded.cpu().detach().numpy() #using decoder\n",
        "    # y_test_ae[start_idx:start_idx+batch_size] = decoded.cpu().detach().numpy() #using decoder #labels.cpu().detach().numpy()\n",
        "\n",
        "    start_idx += batch_size\n",
        "\n",
        "    ### USE X_TEST_AE_ORIG IN THE RF"
      ],
      "metadata": {
        "id": "cy63G8DBqNeg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TESTING THE MODEL:"
      ],
      "metadata": {
        "id": "wVrljdcC_2X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The X_train_ae_overlap shape is:  {X_train_ae_overlap.shape}\")\n",
        "print(f\"The et_train_GT1_overlap shape is:  {et_train_GT1_overlap.shape}\\n\")\n",
        "print(f\"The X_test_ae_orig shape is:  {X_test_ae_orig.shape}\")\n",
        "print(f\"The et_test_GT1 shape is:  {et_test_GT1.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGjwiyr8KV-X",
        "outputId": "f7872337-b85c-403e-8e01-b6122db36739"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The X_train_ae_overlap shape is:  (108821, 50)\n",
            "The et_train_GT1_overlap shape is:  (108821, 1)\n",
            "\n",
            "The X_test_ae_orig shape is:  (26563, 50)\n",
            "The et_test_GT1 shape is:  (26563, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier - USING X FROM ENCODER AND ORIGINAL Y - LABELS FOR TRAINING AND TEST\n",
        "rf = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
        "rf.fit(X_train_ae_overlap, et_train_GT1_overlap.values.ravel()) # #source: https://stackoverflow.com/questions/34165731/a-column-vector-y-was-passed-when-a-1d-array-was-expected\n",
        "\n",
        "print(f'Train Accuracy: {rf.score(X_train_ae_overlap, et_train_GT1_overlap ) * 100:.2f}%')\n",
        "print(f'Test Accuracy: {rf.score(X_test_ae_orig, et_test_GT1) * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvDjr4fGpD-R",
        "outputId": "54e1b9ce-c3e3-4bfb-88aa-65d5241ec3c9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 99.96%\n",
            "Test Accuracy: 44.99%\n"
          ]
        }
      ]
    }
  ]
}